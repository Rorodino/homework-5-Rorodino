{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNksMGsMz3ceHdzigkwgIFS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rorodino/homework-5-Rorodino/blob/main/Copy_of_project5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40hHYsiG-xEU",
        "outputId": "98d0905f-f0b7-4bf9-8f9b-5622263c3488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitted values (PyTorch): [0.5105911  0.47408372 0.42447558 0.40399653 0.49067637 0.45189273\n",
            " 0.4430629  0.47003114 0.41406193 0.47743514]\n",
            "Fitted values (Logistic Regression): [0.57861341 0.52891862 0.45993587 0.43122061 0.55165151 0.49821114\n",
            " 0.48591648 0.52333433 0.44534063 0.53352775]\n"
          ]
        }
      ],
      "source": [
        "#Question 1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load OASIS dataset\n",
        "dat = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv\")\n",
        "\n",
        "# Prepare predictor (t2) and outcome (lesion)\n",
        "X = torch.tensor(dat['T2'].values, dtype=torch.float32).unsqueeze(1)  # shape (n_samples,1)\n",
        "y = torch.tensor(dat['GOLD_Lesions'].values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Define logistic regression model in PyTorch\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # input=1, output=1 (with bias)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))\n",
        "\n",
        "# Instantiate model, loss, optimizer\n",
        "model = LogisticRegressionModel()\n",
        "criterion = nn.BCELoss()  # Binary cross entropy\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train model\n",
        "for epoch in range(5000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Get PyTorch fitted values\n",
        "fitted_values_torch = model(X).detach().numpy()\n",
        "\n",
        "# Fit logistic regression using statsmodels for comparison\n",
        "X_sm = sm.add_constant(dat['T2'])  # add intercept\n",
        "logit_model = sm.Logit(dat['GOLD_Lesions'], X_sm).fit(disp=0)\n",
        "fitted_values_sm = logit_model.predict()\n",
        "\n",
        "# Compare first 10 fitted values\n",
        "print(\"Fitted values (PyTorch):\", fitted_values_torch[:10].flatten())\n",
        "print(\"Fitted values (Logistic Regression):\", fitted_values_sm[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load diamond dataset\n",
        "# Replace with actual path or previous dataset\n",
        "# Example from seaborn (for demonstration)\n",
        "import seaborn as sns\n",
        "df = sns.load_dataset('diamonds')  # this has carat, depth, table, x, y, z, price, etc.\n",
        "\n",
        "# Select predictors and target\n",
        "X = df[['carat', 'depth', 'table', 'x', 'y', 'z']].values\n",
        "y = df['price'].values\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = torch.tensor(scaler.fit_transform(X_train), dtype=torch.float32)\n",
        "X_test = torch.tensor(scaler.transform(X_test), dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Define neural network with 2 hidden layers\n",
        "class DiamondNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(6, 16)   # first hidden layer\n",
        "        self.fc2 = nn.Linear(16, 8)   # second hidden layer\n",
        "        self.fc3 = nn.Linear(8, 1)    # output layer\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return self.fc3(x)  # regression output\n",
        "\n",
        "# Instantiate model, loss, optimizer\n",
        "model = DiamondNN()\n",
        "criterion = nn.MSELoss()          # regression loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train the network\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = model(X_test).detach().numpy()\n",
        "y_true = y_test.numpy()\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "print(\"Test set MSE:\", mse)\n",
        "\n",
        "# Optionally, show first 10 predictions vs actual\n",
        "for i in range(10):\n",
        "    print(f\"Predicted: {y_pred[i][0]:.2f}, Actual: {y_true[i][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DIuWFNxgsPu",
        "outputId": "43548011-4aee-462b-e9d8-885962711e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set MSE: 2055658.375\n",
            "Predicted: 463.19, Actual: 559.00\n",
            "Predicted: 1759.38, Actual: 2201.00\n",
            "Predicted: 1053.30, Actual: 1238.00\n",
            "Predicted: 1206.09, Actual: 1304.00\n",
            "Predicted: 10596.84, Actual: 6901.00\n",
            "Predicted: 4149.19, Actual: 3011.00\n",
            "Predicted: 1655.99, Actual: 1765.00\n",
            "Predicted: 1334.42, Actual: 1679.00\n",
            "Predicted: 1978.69, Actual: 2102.00\n",
            "Predicted: 7071.21, Actual: 4789.00\n"
          ]
        }
      ]
    }
  ]
}